{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7913b565679f184a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T18:20:26.747096Z",
     "start_time": "2024-05-08T18:20:13.658714Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model_name = 'models--google--gemma-7b-it'\n",
    "QnA_dir_path = 'ProteinLMBench.json'\n",
    "with open(QnA_dir_path, 'r') as f:\n",
    "    file_data = json.load(f)\n",
    "os.environ['HUGGINGFACE_HUB_CACHE'] = '/data/llm_models/huggingface/hub'\n",
    "model_path = f'/data/llm_models/{model_name}'\n",
    "if 'models--' in model_name:\n",
    "    fs = f'/data/llm_models/huggingface/hub/{model_name}/snapshots/'\n",
    "    model_path = fs + os.listdir(f'/data/llm_models/huggingface/hub/{model_name}/snapshots/')[0]\n",
    "benchmark_size = 1000\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True, device_map = \"auto\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bd3b66aa7c626ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T18:22:47.316183Z",
     "start_time": "2024-05-08T18:22:46.236751Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "answer_list = [f['answer'] for f in file_data]\n",
    "answer_list = [re.search(r'\\d+', a).group() for a in answer_list]\n",
    "\n",
    "prompt = \"\"\"Please answer the multiple-choice question to the best of your ability by selecting only one correct option. Indicate your choice by stating the option number only. Begin your response with 'The correct option is,' followed by the number of the option. For example, if you believe the correct answer is option 3, respond with 'The correct option is 3.' If you are unsure, make your best guess and follow the same format. Remember to think through each step before deciding. \\n\\n\"\"\"\n",
    "question = []\n",
    "\n",
    "for f in file_data[:benchmark_size]:\n",
    "    options = ''\n",
    "    for o in f['options']:\n",
    "        options += o + '\\n'\n",
    "    sb = prompt + '\\n Question: \\n' + f['question'] + '\\n Options: \\n' + options + '\\n The correct option is'\n",
    "    question.append(sb)\n",
    "\n",
    "chat_model = ('chat' in model_name) or ('Chat' in model_name)\n",
    "if 'Yi' or 'Qwen' in model_name:\n",
    "    chat_model = False\n",
    "inputs = []\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "if 'struct' or 'it' in model_name:\n",
    "    for q in question:\n",
    "        # q = q['prompt']\n",
    "        a = tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": q}], return_tensors=\"pt\").to(\"cuda\")\n",
    "        inputs.append(a)\n",
    "elif not chat_model:\n",
    "    for q in question:\n",
    "        # q = q['prompt']\n",
    "        a = tokenizer(q, return_tensors=\"pt\", padding=True)\n",
    "        input_ids = a.input_ids.to('cuda')\n",
    "        inputs.append(input_ids)\n",
    "else:\n",
    "    inputs = [q for q in question]\n",
    "\n",
    "print(len(inputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c83fd544c8034b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T19:08:00.687684Z",
     "start_time": "2024-05-08T19:08:00.663387Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75530b1167ca1982",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T18:35:41.770926Z",
     "start_time": "2024-05-08T18:22:51.671087Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "output_list = []\n",
    "\n",
    "temp = 0.8\n",
    "mnt = 15\n",
    "for q in tqdm(inputs[:]):\n",
    "    if chat_model:\n",
    "        try:\n",
    "            if 'Mistral' in model_name:\n",
    "                output_list.append(model.chat(tokenizer, q, do_sample=True, max_new_tokens=mnt, temperature=temp, history=[], eos_token_id=2, pad_token_id=2))\n",
    "            else:\n",
    "                output_list.append(model.chat(tokenizer, q, max_new_tokens=mnt, do_sample=True, temperature=temp, history=[]))\n",
    "        except:\n",
    "            output_list.append(model.generate(q, max_new_tokens=mnt, do_sample=True, temperature=temp))\n",
    "    else:\n",
    "        if 'Mistral' in model_name:\n",
    "            output_list.append(model.generate(q, max_new_tokens=mnt,do_sample=True, temperature=temp, eos_token_id=2, pad_token_id=2))\n",
    "        elif 'llama3-8B' or 'Llama-3' in model_name:\n",
    "            output_list.append(model.generate(q, max_new_tokens=mnt,do_sample=True, temperature=temp, eos_token_id=128001, pad_token_id=128001))\n",
    "        elif 'falcon' in model_name:\n",
    "            output_list.append(model.generate(q, max_new_tokens=mnt,do_sample=True, temperature=temp, eos_token_id=11, pad_token_id=11))\n",
    "        else:\n",
    "            output_list.append(model.generate(q, max_new_tokens=mnt, do_sample=True,temperature=temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcfe2d9444475b2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T18:35:59.825707Z",
     "start_time": "2024-05-08T18:35:59.572578Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "after = []\n",
    "if not chat_model:\n",
    "    lst = [tokenizer.decode(i[0], skip_special_tokens=True) for i in output_list]\n",
    "    for i, j in zip(lst, question):\n",
    "        after.append(i.replace(j, ''))\n",
    "else:\n",
    "    for i, j in zip(output_list, question):\n",
    "        after.append(i[0].replace(j, ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a01389b79cd07620",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T18:36:00.636267Z",
     "start_time": "2024-05-08T18:36:00.579869Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad7bf0e6f65c0854",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T19:09:02.331680Z",
     "start_time": "2024-05-08T19:09:02.309054Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "v_ans = []\n",
    "non_number = 0\n",
    "for o in after:\n",
    "    try:\n",
    "        v_ans.append(re.search(r'\\d+', o).group())\n",
    "    except:\n",
    "        non_number += 1\n",
    "        v_ans.append(\"None\")\n",
    "\n",
    "print(non_number)\n",
    "psd = 0\n",
    "# wrong_list = []\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "formatted_time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "if \"/\" in model_name:\n",
    "    model_name = model_name.split(\"/\")[2]\n",
    "\n",
    "with open(f'result/final_result_{benchmark_size}_{formatted_time}_{model_name}.json', 'w') as jj:\n",
    "    json.dump(after, jj)\n",
    "\n",
    "with open(f'result/final_compare_{benchmark_size}_{formatted_time}_{model_name}.txt', 'w') as results:\n",
    "    for i in range(len(v_ans)):\n",
    "        # print(i)\n",
    "        if v_ans[i] != answer_list[i]:\n",
    "            results.write(str(v_ans[i]) + \"   \"+ str(answer_list[i]))\n",
    "            results.write(\"\\n\")\n",
    "            continue\n",
    "        else:\n",
    "            results.write(\"Right\")\n",
    "            psd+=1\n",
    "            results.write(\"\\n\")\n",
    "\n",
    "accuracy = psd/len(v_ans)\n",
    "print('correct rate: ' + str(psd / len(v_ans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cce574485498a2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T17:38:01.430813Z",
     "start_time": "2024-04-29T17:38:01.417544Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('ProteinLMBench.json', 'r') as f:\n",
    "    file_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c72f564632b851f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T17:38:04.285446Z",
     "start_time": "2024-04-29T17:38:04.270439Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad = []\n",
    "for t in file_data:\n",
    "    if 'options' not in t:\n",
    "        bad.append(t)\n",
    "        continue\n",
    "    for i in range(6):\n",
    "        try:\n",
    "            t[f'option {i+1}'] = t['options'][i][10:]\n",
    "        except IndexError:\n",
    "            continue\n",
    "\n",
    "    # Remove the original 'options' key if it exists\n",
    "    t.pop('options', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12b7539f38f01052",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T17:38:21.058335Z",
     "start_time": "2024-04-29T17:38:20.843966Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a8ec640dc6c0b18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T17:40:56.752465Z",
     "start_time": "2024-04-29T17:40:56.716289Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(file_data)\n",
    "\n",
    "# Convert DataFrame to CSV file\n",
    "df.to_csv('ProteinLMBench.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58278b2fa29f330a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T17:45:53.165254Z",
     "start_time": "2024-04-29T17:45:53.138877Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = pd.read_csv('ProteinLMBench.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9df795d51691d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T17:48:18.654181Z",
     "start_time": "2024-04-29T17:48:18.645437Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_order = ['question', 'option 1','option 2','option 3', 'option 4','option 5','option 6','answer', 'explanation']\n",
    "# Reorder the columns\n",
    "c = c[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "308d33401e4318bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T17:49:36.931330Z",
     "start_time": "2024-04-29T17:49:36.901889Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.to_csv('ProteinLMBench.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
